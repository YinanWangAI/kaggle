a <- sum_three()
a(1, 2, 3)
sum_two <- function(x, y) {
return(x + y)
}
sum_three <- function() {
foo <- function(a, b, c) {
return(sum_two(a, b) + c)
}
return(foo)
}
a <- sum_three()
a(1, 2, 3)
a <- c(1, 2, 3)
is.vector(a)
is.atomic(a)
a <- list(1, 2, 3)
a
is.vector(a)
is.atomic(a)
is.list(a)
1 + 5i
is.complex(1)
is.complex(1 + 0i)
is.complex(1 + 5i)
is.integer(1)
is.integer(1L)
is.logical(NA)
is.logical(1)
is.logical(T)
is.integer(NA)
NA_integer_
is.integer(NA_integer_)
c(1, 'a')
c(1L, 'a')
c(1L, 2)
is.integer(c(1L, 2))
is.integer(c(1L, 2L))
typeof(c(1L, 2L))
c(1, c(2, 3))
list(1, c(2, 3))
c(list(1, c(2, 3)))
c(list(1, c(2, 3)), 4)
is.vector(c(list(1, c(2, 3)), 4))
is.atomic(c(list(1, c(2, 3)), 4))
is.list(c(list(1, c(2, 3)), 4))
typeof(c(list(1, c(2, 3)), 4))
str(c(list(1, c(2, 3)), 4))
c(list(1, 2), c(3, 4))
as.vector(c(list(1, 2), c(3, 4)))
unlsit(c(list(1, 2), c(3, 4)))
unlist(c(list(1, 2), c(3, 4)))
a <- c(1, 2, 3)
str(a)
structure(a)
a <- list(c(1, 2, 3), 'a', T)
str(a)
structure(a)
a
attr(a)
attributes(a)
attr(a, "a_name") <- "list.a"
str(a)
structure(a)
a
structure(a)
attributes(a)
x <- c(1, 2, 3)
names(x)
names(a)
x <- factor('a', 'b', 'c')
x
x <- factor(c('a', 'b', 'c'))
x
typeof(x)
class(x)
class(a)
x[1] <- 'd'
x
c(1, x)
x <- factor(c('a', 'b', 'c'))
c(1, x)
list(c(1, x))
list(1, x)
array(matrix(1:9, 3, 3), matrix(1:4, 2, 2))
y <- array(matrix(1:9, 3, 3), matrix(1:4, 2, 2))
y[1]
str(y)
y[[1]]
y[1:9]
y[1:12]
y[, 1]
dim(y)
attributes(y)
y
length(y)
z <- matrix(1:9, 3, 3)
z
length(z)
b <- array(1:12, c(2, 3, 2))
b
str(b)
length(b)
dim(b)
dim(x)
x
dim(y)
is.matrix(b)
is.matrix(z)
is.array(z)
is.array(b)
is.array(y)
l <- list(1:3, "a", T, 1.0) dim(l) <- c(2, 2)
l <- list(1:3, "a", T, 1.0)
dim(l) <- c(2, 2)
l
l[1, 1]
l[1, 2]
df <- data.frame(
x = 1:3,
y = c('a', 'b', 'c')
)
df
str(df)
df <- data.frame(
x = 1:3,
y = c('a', 'b', 'c'),
stringsAsFactors = F
)
str(df)
typeof(df)
class(df)
x <- c(3, 5, 1, 0, 7)
order(x)
x[order(x)]
rank(x)
order(x)
x
sort(x)
x[1.1]
x[1]
x[-1]
x[-c(1, 4)]
x[c(-1, -4)]
x[NA]
x[c(1, NA)]
letters()
letters
LETTERS
x <- list(c(1, 2, 3), 'a', T)
x
x[1]
x[2]
x[1:2]
vals <- outer(1:5, 1:5, FUN = "paste", sep = ",")
vals
outer(1:5, 1:5)
?outer
vals[1]
vals[c(4, 10)]
df
df['x']
str(df['x'])
dt[, 'x']
df[, 'x']
str(df[, 'x'])
try(1)
try(1 / 0)
try(1 / 'a')
a <- try(1 / 'a')
b <- list(a = list(b = list(c = list(d = 1))))
b
b[[c("a", "b", "c", "d")]]
b[[c("a", "b", "c", "de")]]
lm
x <- c(1, 2, 3)
x[T] <- -1
x
x <- c(1, 2, 3)
x[c(T, F)] <- -1
x
df['x']
df[, 'x']
df[] <- df[, 'x']
df
df[] <- df[, 'x']
df
grades <- sample(3, 5, rep = T)
sample(3, 5, rep = T)
sample(3, 5, rep = F)
info <- data.frame(
grade = 1:3,
desc = c("Poor", "Good", "Excellent"),
fail = c(T, F, F)
)
info
match(grades, info$grade)
grades
id <- match(grades, info$grade)
info[id, ]
x <- c(1, 2, 3)
x[order(x)[1]]
x[order(x)[2]]
':'
:
`:`
a <- c(T, F, T)
b <- c(F, T, T)
a & b
a && b
a <- c(T, F, T)
b <- c(T, T, T)
a && b
a & b
xor(a, b)
length(1)
length(T)
length(F)
length(NA)
length(NULL)
data
date
date()
environment(date)
f <- function(x) return(x)
f
environment(f)
body(date)
body(f)
typeof(f)
class(f)
attributes(f)
attributes(date)
sum
.Primitive()
.Primitive
x <- 1
h <- function() {
y <- 2
i <- function() {
z <- 3
c(x, y, z)
}
i()
}
h()
j <- function(x) {
y <- 2
function() { c(x, y)
} }
k <- j(1)
k()
foo <- function(a, b) {
if (missing(a)) stop("no a")
if (missing(b)) stop("no b")
return(a + b)
}
foo()
foo(1)
foo(1, 2)
foo <- function(x = ls()) {
a <- 1
return(x)
}
foo()
foo(ls())
NULL > 0
plot
plot.default
"+" <- function(a, b) return(paste(a, b))
1 + 1
rm("+")
1+1
"%+%" <- function(a, b) return(paste(a, b))
'a' %+% 'b'
'a' %+% 'b' %+% 'c'
`%+%` <- function(a, b) return(paste(a, b))
'a' %+% 'b' %+% 'c'
`%+` <- function(a, b) return(paste(a, b))
'a' %+ 'b' %+ 'c'
`%+`(1, 2)
`%+%` <- function(a, b) return(paste(a, b))
'a' %+% 'b' %+% 'c'
"second<-" <- function(x, value) {
x[2] <- value
x
}
x <- 1:10
second(x) <- 5L
x
second(x) <- 'a'
x
library(pryr)
.libPaths()
I(x)
x
mean
sum
methods("mean")
methods("plot")
MyClass <- structure(list(), class = "MyClass")
f <- function(x) {
UseMethod('f')
}
f.MyClass <- function(x) {
print("Call f.MyClass")
}
f(MyClass)
f.MyClass <- function(x) {
print(x)
print("Call f.MyClass")
}
f(MyClass)
plot.fuck <- function(x) {
print('plot fuck')
}
MyFuck <- structure(list(), class = 'fuck')
plot(MyFuck)
class(MyFuck)
test <- list(c(1, 2, 3))
test
class(test)
class(test) <- "fuck"
plot(test)
setClass(
"Person",
slots = list(
name = "chracter",
age = "numeric"
)
)
setClass(
"Person",
slots = list(
name = "character",
age = "numeric"
)
)
setClass(
"Employee",
slots = list(boss = "Person"),
contains = Person
)
setClass(
"Employee",
slots = list(boss = "Person"),
contains = "Person"
)
new("Person", name = "Alice", age = 32)
alice <- new("Person", name = "Alice", age = 32)
john <- new("Employee", name = "john", age = 27, boss = alice)
alice
john
alice@name
library(ggplot2)
.libPaths()
library(ggplot2)
library(randomForest)
library(readr)
install.packages("readr")
library(readr)
set.seed(0)
setwd("~/kaggle/digit_recognizer/")
numTrain <- 10000
numTrees <- 25
train <- read_csv("train.csv")
train <- read_csv("train.csv")
test <- read_csv("test.csv")
rows <- sample(1:nrow(train), numTrain)
labels <- as.factor(train[rows,1])
train <- train[rows,-1]
rf <- randomForest(train, labels, xtest=test, ntree=numTrees)
predictions <- data.frame(ImageId=1:nrow(test), Label=levels(labels)[rf$test$predicted])
head(predictions)
randomForest
library(data.table)
library(dplyr)
library(randomForest)
library(mxnet)
setwd("~/kaggle/digit_recognizer/")
load_data <- function(train_path = "data/train.csv",
test_path = "data/test.csv",
val_path = NA,
val_prop = 0.1,
seed = 0) {
#' load data from raw file
#'
#' @param train_path String, the path of training data
#' @param test_path String, the path of test data
#' @param val_path String, optional, the path of validation data, if not
#' supplied, the training data will be divided into training and validation
#' data
#' @param val_prop Float, from 0 to 1,if validation data is not supplied,
#'  the val_prop proportion of training data will serve as validation data
#'  @param seed Int, arguments for set.seed()
#'  @return list with three elements (training, test and validation data)
train <- fread(train_path)
test <- fread(test_path)
if (is.na(val_path)) {
if (val_prop < 0 | val_prop >= 1) stop("Invalid validation
proportion (val_prop)")
if (val_prop == 0) {
warning("No validation data")
return(list(train, test, NA))
}
set.seed(seed)
train_number <- nrow(train)
train_row <- sample(train_number, floor(train_number * (1 - val_prop)),
replace = F)
val_row <- setdiff(1:train_number, train_row)
val <- train[val_row, ]
train <- train[train_row, ]
} else {
val <- fread(val_path)
}
return(list(train, test, val))
}
make_submission_file <- function(x, path) {
submit <- data.table(
ImageID = 1:length(x),
Label = x
)
write.csv(submit, file = path, row.names = F)
}
# load training, validation and test data---------------------------------------
all_data <- load_data()
train <- as.data.table(data.frame(all_data[1]))
test <- as.data.table(data.frame(all_data[2]))
valid <- as.data.table(data.frame(all_data[3]))
train_all <- rbind(train, valid)
# benchmark validation error by random forest-----------------------------------
train_x <- as.matrix(train[, 2:ncol(train), with = F])
train_y <- as.factor(train[[1]])
valid_x <- as.matrix(valid[, 2:ncol(valid), with = F])
valid_y <- as.factor(valid[[1]])
train_all_x <- as.matrix(train_all[, 2:ncol(train_all), with = F])
train_all_y <- as.factor(train_all[[1]])
test_x <- as.matrix(test)
train_array <- t(train_x)
dim(train_array) <- c(28, 28, 1, nrow(train_x))
valid_array <- t(valid_x)
dim(valid_array) <- c(28, 28, 1, nrow(valid_x))
train_all_array <- t(train_all_x)
dim(train_all_array) <- c(28, 28, 1, nrow(train_all_x))
test_array <- t(test_x)
dim(test_array) <- c(28, 28, 1, nrow(test_x))
data <- mx.symbol.Variable("data")
conv1 <- mx.symbol.Convolution(data = data, kernel = c(5, 5), num_filter = 128)
conv1_activate <- mx.symbol.Activation(data = conv1, act_type = "relu")
pool1 <- mx.symbol.Pooling(data = conv1_activate, pool_type = "max",
kernel = c(2, 2), stride = c(2, 2))
# second convolutional layer
conv2 <- mx.symbol.Convolution(data = pool1, kernel = c(5, 5), num_filter = 64)
conv2_activate <- mx.symbol.Activation(data = conv2, act_type = "relu")
pool2 <- mx.symbol.Pooling(data = conv2_activate, pool_type = "max",
kernel = c(2, 2), stride = c(2, 2))
# first full connected layer
flatten <- mx.symbol.Flatten(pool2)
fc1 <- mx.symbol.FullyConnected(data = flatten, num_hidden = 20)
fc1_activate <- mx.symbol.Activation(data = fc1, act_type = "relu")
# output layer
fc2 <- mx.symbol.FullyConnected(data = fc1_activate, num_hidden = 10)
cost <- mx.symbol.SoftmaxOutput(data = fc2)
cnn <- mx.model.FeedForward.create(
cost,
X = train_array, y = as.numeric(as.character(train_y)),
num.round = 10, array.batch.size = 100,
learning.rate = 0.05, momentum = 0.9,
eval.metric = mx.metric.accuracy)
cnn_pred <- predict(cnn, valid.array)
pred_label <- max.col(t(cnn_pred)) - 1
valid_accuracy <- sum(as.numeric(as.character(valid_y)) == pred_label) /
length(pred_label)
cnn_pred <- predict(cnn, valid_array)
pred_label <- max.col(t(cnn_pred)) - 1
valid_accuracy <- sum(as.numeric(as.character(valid_y)) == pred_label) /
length(pred_label)
data <- mx.symbol.Variable("data")
# first convolutional layer
conv1 <- mx.symbol.Convolution(data = data, kernel = c(5, 5), num_filter = 32)
conv1_activate <- mx.symbol.Activation(data = conv1, act_type = "relu")
pool1 <- mx.symbol.Pooling(data = conv1_activate, pool_type = "max",
kernel = c(2, 2), stride = c(2, 2))
# second convolutional layer
conv2 <- mx.symbol.Convolution(data = pool1, kernel = c(5, 5), num_filter = 16)
conv2_activate <- mx.symbol.Activation(data = conv2, act_type = "relu")
pool2 <- mx.symbol.Pooling(data = conv2_activate, pool_type = "max",
kernel = c(2, 2), stride = c(2, 2))
# first full connected layer
flatten <- mx.symbol.Flatten(pool2)
fc1 <- mx.symbol.FullyConnected(data = flatten, num_hidden = 20)
fc1_activate <- mx.symbol.Activation(data = fc1, act_type = "relu")
# output layer
fc2 <- mx.symbol.FullyConnected(data = fc1_activate, num_hidden = 10)
cost <- mx.symbol.SoftmaxOutput(data = fc2)
# cnn <- mx.model.FeedForward.create(
#   cost, X = train_array, y = train_y,
#   num.round = 10, array.batch.size = 100,
#   learning.rate = 0.05, momentum = 0.9, wd = 0.00001,
#   eval.metric=mx.metric.accuracy,
#   epoch.end.callback = mx.callback.log.train.metric(100))
cnn <- mx.model.FeedForward.create(
cost,
X = train_array, y = as.numeric(as.character(train_y)),
num.round = 10, array.batch.size = 100,
learning.rate = 0.05, momentum = 0.9,
eval.metric = mx.metric.accuracy)
install.packages("drat", repos="https://cran.rstudio.com")
drat:::addRepo("dmlc")
install.packages("mxnet")
drat:::addRepo("dmlc")
install.packages("mxnet")
